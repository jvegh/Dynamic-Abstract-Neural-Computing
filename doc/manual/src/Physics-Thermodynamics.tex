% Thermodynamics for ions


\section{Ions' thermodynamics\label{sec:Physics-Thermodynamics}}



Although science knows from the beginning of scientific thinking that the material world around us
comprises discrete objects (particles) that cannot be divided without limitations at a given abstraction level,
most of the scientific laws were devised for a continuous material,
such as the laws about pressure and current.
Our laws about mass and charge (and so: on energy, impulse and so on),
are about discrete concepts.
Furthermore, science has created abstract concepts such as space and time, mass and charge, continuous and discrete views. \textit{Classical science considered only one such concept at a time.} Thermodynamics was the first discipline
which connected two of those separated attributes, the discrete and continuous views.


\subsection[Why different]{Why cellular thermodynamics is different\label{sec:Physics-ThermodynamicsWhyDifferent}}
This section recalls the contents of section~\ref{sec:Physics-Dichotomies} from the viewpoint of thermodynamics.
As we discussed, we can handle \hypertarget{ThermodynamicsSpecialties}{atomicity in different abstractions},
as charge-less or mass-less points (but anyhow: 'material point' as A.~Einstein coined~\cite{EinsteinSpecial:1905}). We derived laws for a single interaction,
see Newton's Law of Universal Gravitation and Coulomb's law.
\index{Coulomb's law}
However, ions require different thinking~\cite{VeghNon-ordinaryLaws:2025}: \textit{thermodynamics is about non-interacting particles}.
In the frame of classical science, the interactions are instant,
and so the interaction speeds are the same. Evidence shows that
this is not the case for electrodiffusion; they differ by about six orders of magnitude. The assumption of classic science that 
everything occurs at the same time evidently cannot be applied; correspondingly, the diffusion coefficient of electrodiffusion has yet to be discovered.


\subsubsection[Dual substances]{Dual substances\label{sec:Physics-ThermodynamicsDual}}

The ions as 'material points' (having charge and mass) can be abstracted
that they have a behavior that there are \textit{two} underlying interactions and experience two different force fields that cannot be separated further;
correspondingly they have less simple laws of forces and motion.
Classical science describes one type of forces using laws of electricity (the points have charge but no mass),
another type using laws of mechanics (the points have mass but no charge).
We must recall that thermodynamics is about non-interacting particles (except their direct collisions as hard-ball points). When speaking about ions, the volume elements in the phase space are not independent: the energy and momentum of a particle depend on the other particles.

\subsubsection[Mixing speeds]{Mixing speeds\label{sec:Physics-ThermodynamicsMixingSpeeds}}

What truly sets ions' thermodynamics apart in physics is the absence of a direct
equivalent of the Maxwell-equations. 
By introducing time derivatives by Eqs.~(\ref{eq:Nernst-dVdt}) and~(\ref{eq:Nernst-dCdt}), we can provide their equivalent equations that describe the relation between concentration
and potential for the case when the first time derivative of the position coordinate is not zero.
The practical difficulty is that the diffusion speed is by several orders of magnitude smaller than that of the 
\gls{EM}
interaction.
Furthermore, the applied electric field speeds up the ions
to \hyperlink{MixingSpeeds}{potential-assisted or -accelerated speeds}, and 
% (and also that of the "slow ion" current), see Eq.~(\ref{eq:PhysicsGradientRatio});
classical physics is not prepared to handle mixing interaction speeds.


In classical physics, the 
\gls{EM}
interaction is instant, so the time
derivatives of the electric and magnetic fields can change simultaneously.
In the approximation we use, we consider the 
\gls{EM}
speed infinitely
high -- in the spirit of 'classical physics' -- and
we consider the finite speed of ions using physical approximations,
which are simplified representations of the actual physical processes.
In our mathematical model, \emph{the electric field gradient acts
instantly on the charge, but the effect of the concentration gradient
reaches its position with some delay}.
In this unique field, the chemical
concentration gradient and the electrical field generate each other at different
pace, presenting a fascinating departure from traditional ('ordinary') physics. Another speed-related difference is that we must introduce
-- among others-- local and global conservation laws,
similar to the case of general theory of relativity.


\subsubsection[Microscopic vs macroscopic]{Microscopic vs macroscopic\label{sec:Physics-Microscopic}}

The macroscopic features (such as pressure, temperature, 
potential, and concentration) of systems of 'material points'
are interpreted as having statistical
behavior and their laws are discussed by the scientific discipline
\hypertarget{Thermodynamics}{thermodynamics}.
Its notions drastically differ from the ones of
classical fields. 
%Recall, however, that thermodynamics is about
%non-interacting (except direct collisions) particles.
Here the concepts such as 'temperature' or 'pressure' are a generalization: 
a homogeneous distribution means that classical physical substances 
(such as momentum and energy) have a well-established distribution
instead of a single vakue or uniform values of parameters. 
At the same time (in infinitely large volumes) the macroscopic parameters
'concentration' and 'potential' (notice that they are based on the single-interaction abstractions 'mass' and 'charge', respectively) are simple densities,
although to interpret them, a large number of particles must be considered.
For the more careful experimenter, it is evident that this homogeneity
is a dynamical one: particles' movement changes it continuously and 
it is constant only as a statistical average.

\subsubsection{Limited volumes\label{sec:Physics-ThermoLimited}}
\index{cell!limited volume}

The processes happen at the boundaries of the microscopic and macroscopic worlds, and we
must consider different interactions at different speeds. To describe
the phenomena, which are neither purely microscopic nor macroscopic, more than one abstraction must be used. Still, they show the behavior
of both worlds. Furthermore, they change their behavior during the
course of the studied process. The inappropriate handling of mixing interaction speeds lead to 'non-ordinary' behavior and one can conclude 'non-ordinary' laws when uses the appropriate approximation(s).
We need a more careful handling (and more approximations) when we consider the interactions in a finite volume, with strongly different conditions on its boundaries. 
We need to conduct case studies and apply casual approximations to describe
the phenomena, which are neither purely microscopic nor macroscopic
and where more than one abstraction must be used.
It is important
to remember that we are dealing with a mixture of macroscopic and microscopic
descriptions, and this understanding is a crucial aspect of our research.

\subsubsection{Constraints\label{sec:Physics-ThermoConstraints}}

Newton's laws of motion apply also to ions in the cell, given that 
they are independent of how the exerting forces are generated.
As we discuss in section~\ref{sec:Physics-SteadyState}, the "special construction" of living matter leads to cases when "conditional counterforces" may apply. Furthermore,
there are constraints arising from the structure of the living matter,
and they move the 'material point' in a viscous media instead of vacuum;
furthermore, the balanced states, as well as the processes from and to
those states, are described by the interplay of those forces.


\subsubsection[Reciprocal relations]{Reciprocal relations\label{sec:Physics-ThermodynamicsReciprocal}}

The distributions, however, can be calculated for charge-less and size-less 'material points' only.
The interference of those forces and that they affect two different 
features of the atomic particles lead to unusual disciplinary consequences.
 For his discovery of the \hypertarget{Onsager_relations}{reciprocal relations in thermodynamics},
 Lars Onsager was awarded the 1968 Nobel Prize in Chemistry.
 The presentation speech referred to his result that "Onsager's reciprocal relations represent a further law making a thermodynamic study of irreversible processes possible". In that sense, \textit{we provide mathematical equations of the fourth law of thermodynamics} in section~\ref{sec:Physics-LawsOfMotion}.
The experimental verification~\cite{OnsagerExperimental:1959} of that law mentions "the well-known difficulty of carrying out these experiments". 
By using our relations between the electrical and chemical diffusion, we can overcome that experimental difficulty.
The significance of our Eq.(\ref{eq:PhysicsGradientRatio}) is, that one can derive the speed of 
electrodiffusion in electrolytes, which are otherwise not measurable ("hopping in a breeze"~\cite{KochBiophysics:1999}: we would have to measure potential changes 
at distances of the size of the electrodes, 
with picosec resolution while the electrolytic electrodes 
cause nearly msec delays).


\subsubsection{Electric charges\label{sec:Physics-ThermoElectric}}
In our research, the key point is that life (including neural processes) is based (mainly)
 on \hypertarget{ElectrodiffusionProcesses}{thermo-electric processes}.
The contradictions and duality (mainly) arise from the
enormously different interaction speeds of the electric and diffusion
processes. In our approach, we divide ion movements into stages,
based on the speed of the dominating electric interaction. We introduce
diffusion (or \emph{potential-less}), \emph{potential-assisted} (based
on the mutual repulsion only), and \emph{potential-accelerated} (internal 
voltage on biological components accelerates the ions) speeds. 
In some cases, the diffusion and electric processes follow each other in separate phases, so in some phase, they can be better approximated as "net" electrical system, combining "fast" and "slow" currents.
\index{current!slow}\index{current!fast}
\index{speed!potential-related}
\index{interaction!dominant}
\index{interaction!speed}
\index{speed!interaction}
We show that the processes can
be staged in such a way that in addition to the dominant interaction,
only one more significant interaction remains on the stage, and we can work
out a physics-based approximation that a mathematical formalism can
describe.


\subsection{Statistical mechanics\label{sec:Physics-Statistical}}

Thermodynamics is a somewhat misunderstood branch of physics. As its name suggests, it deals with heat, work, and temperature, and their relationship to energy, entropy, and the physical properties of matter.
However, it is based on statistical mechanics, which combines two fundamentally different concepts of nature.
Ever since physics discovered that things, initially thought to be continuous, are quantized, it has been dealing with matter in a kind of double consciousness. In some ways, we view gases and fluids as continuous, while in others, we view them as discrete.
Although we know that electricity consists of elementary charges, we describe it essentially in terms of continuous quantities. We think about the continuous medium as comprising hard-shelled balls, but their distribution is continuous.

To handle discrete objects in a continuous distribution, Ludwig Boltzmann introduced the ingenious idea that
we use use a continuous \textit{probability distribution} in a \textit{phase space} to form ensembles. That is,
we assume that a well-defined  $f(\mathbf{r},\mathbf{p},t)$
probability distribution function of the position vector $\mathbf{r}$ and the momentum vector $\mathbf{p}$ of individual particles exists at every single moment $t$, and the volume element $d^3\mathbf{r}\,d^3\mathbf{p}$ in the phase-space defines an ensemble; furthermore, the integral of the distribution over that ensemble gives the probability that the volume contains
\begin{equation}
	dN=f(\mathbf{r},\mathbf{p},t)\,d^3\mathbf{r}\,d^3\mathbf{p}\label{eq:Boltzmann}
\end{equation}
particles which have identical positions and moments in that region, at an instant of time. From this point on, we assume that the statistical estimation is sufficiently good (the probability function is sufficiently 'dense' or the volume element is sufficiently large).
We consider that the probable number $dN$ is the actual  number, and 
consider that the same forces affect all particles in the same way,
as the laws of science describe it. Notice that the individual particles are independent, so they \textit{must not interact with each other};
they are affected only by external forces. 
An internal force would change the infinitesimal volume
in the considered infinitesimal period.


"The real strength of thermodynamics lies in the collective phenomena. Temperature, pressure,
heat, and so forth, are terms from the world of ensembles."~\cite{HeimburgPhysikOfNerves:2009}
Notice that here we are on the boundary of the continuous and
particle-like views of a system: we select the particles as if we were
handling a continuum, but calculating their position and momentum individually,
under the exertion of a jointly defined force.
In thermodynamics, the continuous and the quantized views of nature
are connected. The idea was to not handle the enormous amount of particles individually; instead, replace the concrete particles
with a probability that they are at a given position (in the phase space). \textit{The abstract mathematical laws of probability and statistics
have their conditions of applicability. The task of physics was to 
determine which conditions enable us to use those abstract laws 
for actual physical systems}, also when combining the statistical and particle views of electrons. \textit{We must discuss
whether changing the charge carrier and the medium where charge is transmitted changes the
conditions of applicability.} In other words,
\textit{we must scrutinize how much the laws of electricity, which are based on the statistical behavior of electrons in solids as a medium,
can describe the statistical behavior of ions in the special medium that biology represents.}



The general equation to consider the force exerted on the particles is usually the composition
\begin{equation}
	\frac{df}{dt} = \biggl( \frac{\partial f}{\partial t}\biggr)_{ext}
	+ \biggl( \frac{\partial f}{\partial t}\biggr)_{diff}
	+ \biggl( \frac{\partial f}{\partial t}\biggr)_{coll}
	\biggl(	+ \biggl( \frac{\partial f}{\partial t}\biggr)_{constr}\biggr)
	\label{eq:BoltzmanForces}
\end{equation}
\noindent
The formula considers an external force (essential: not exerted by another particle), the diffusion, the collisions that can change the particles' coordinates in the phase space, and the constrain force that originate from the mediaum and the container. Since that change must be the same for all particles,
the assumption is valid only when the particles do not interact,
or the medium in which they interact averages their interaction, 
that way, providing a (statistically) constant external force.
The last term in Eq.(\ref{eq:BoltzmanForces}) was added to consider the constraints in the system (in biology, such mechanical obstacles are represented by membranes, tube walls, caps on ion channels; a hard-to-consider conditional term that comes from the "construction" of the living matter).
%A key assumption of thermodynamics is that a force "instantly" acts on each particle.

A more usual form (with our contrain force included) of the equation is
\begin{equation}
	\frac{\partial f}{\partial t} + \frac{\mathbf{p}}{m}\times \nabla f
	+ \mathbf{F} \times \frac{\partial f}{\mathbf{p}}
	=\biggl(\frac{\partial f}{\partial t}\biggr)_{coll}
	\biggl(	+ \biggl( \frac{\partial f}{\partial t}\biggr)_{constr}\biggr)
	\label{eq:BoltzmannMass}
\end{equation}
Notice the explicit role of particles' mass:
even if there were no other fundamental differences between the 
solid-state-based and electrolyte-based electricity, the $\approx 50,000$ factor between the masses of the charge carriers, alone, would introduce drastic deviations
in the equations describing them.
Furthermore, the terms combine describing individual particles with a description of probabilistic groups of particles; practically, continuous and quantized matter.


The best-known case is when there is no long-range interaction
between the colliding particles, see above; the case of gases is the textbook example of thermodynamics.
The most problematic term, in general, is the one on the right side of Eq.(\ref{eq:BoltzmanForces}) that describes 
the effect of collisions between particles, which is topped in biology by the effect of the limited volume ("the construction"). The above collisionless equation is relatively simple. If long-range interactions are present, they can be aggregated in some cases. Physically, in plasmas, the swift free electrons and in solids, the heavy ions at fixed positions provide such aggregated force fielda, and one can describe the collisionless movement of the charge carriers (ions in plasmas and electrons in solids) in that field also in the presence of long-range interaction. 

Correspondingly, there are two major branches of applying Eq.(\ref{eq:Boltzmann}) 
for systems with collisions (the classical thermodynamics for particles
without electric charge, such as gases) and without collisions (in plasmas, the swift and light electrons provide a strong and uniform electric field, and the electrons do not collide directly; furthermore, the long-distance positive charge of the freely moving ions prevents direct collisions).
 A common element in those two branches is the assumption that \textit{the cell
	in the phase space remains unchanged and the force that is exerted 
	on the particles is identical and instant}.
Classical electricity, the case of electrons in solids, corresponds to the case
of moving under the effect of an external force (electrical field)
and suffering inelastic collisions with the ions that are fixed to the 
gridpoints. The gridpoints convert the lost energy to heat,  so we can consider rest of the system collisionless.
In this case, the particles form a kind of cloud, so they do not exert
force on each other, at least in a statistical sense. The ions in electrolytes, however, represent a drastically different case. There exists a 
long-range interaction between the ions; moreover, the ions collide
with the neutral particles and the neutral particles with each other. On the one side, the overwhelming majority of the particles is not ionized, so the neutral particles define the features of the medium,
so the behavior of the electrolytes is similar to that of the 
non-interacting particles. However, in the processes studied by
biology, the low proportion of ionized particles dominate,
so the behavior of ions in electrolytes is somewhat similar
to that of the electrons in solids.
 The ions in electrolytes represent a 
very different class.
That is, to describe them mathematically,
we must add one more term to Eq.(\ref{eq:BoltzmanForces}) to consider
their long-range interaction plus one more term for their movement in speed-dependent interaction with the viscous medium. When describing electrical phenomena, 
in the case of having electrons in solids, we can neglect the  
collisions (in the terminology below: the thermodynamic term):
\index{electron cloud}
the cloud mediates the charge transfer "instantly", allowing a "one electron in, one electron out" mode of the charge transfer.
In the case of ions in electrolytes,
the ions can collide with the neutral particles and each other, and the 
strong, long-distance Coulomb interaction contributes
\index{Coulomb interaction}
a force that makes (part of) particles non-independent,
making the applicability of Eq.(\ref{eq:Boltzmann}) questionable.


We see that for the case of ions moving in biological electrolytes, neither of the above assumptions is valid (not to mention that the system is not closed so various constraint forces may affect the ions' movement; furthermore, the medium not only "resists" ion movement due to collisions with neural molecules  but it can be chemically and electrically active). 
The ions have a long-range Coulomb interaction with each other,
so they can freely change their positions as well,
that \textit{changes the cell size $d^3\mathbf{r}d^3\mathbf{p}$}.
(This way, the derivative of the momentum is also present
in the corresponding equations.)


A key assumption of thermodynamics is that a force "instantly" acts on each particle.
External forces that exert an effect on the ions act instantly:
the case of biological electrolytes represents a combination of instant collisions
with long-range Coulomb interactions.
\textit{The thermodynamic effect (the collision) of a particle arrives at the other particle later than its electric effect.}
The classical disciplinary physics is not prepared for such a case:
it handles all processes at the same (instant) speed. This is
one of the fundamental issues why the usual thermodynamics handling
cannot successfully describe biological systems.


The essential points of Boltzmann's general equation are that \textit{the force acting on the particles is instantaneous, the particles only come into contact by direct collisions, the volume is infinite, the number of particles is sufficiently large, and the system is closed}.
Only with these assumptions can we assume that the volume in the phase space does not change. In the case of neutral atoms or molecules in a large, closed volume, the conditions are met, and Boltzmann's equations describe the observed behavior of the systems.
Another approach can be derived (the so-called Vlasov equations) when there is
a long-range interaction between particles (for example, the Coulomb interaction
between ions of the same charge), which excludes direct particle collisions.
The latter describes, for example, plasmas in which atoms are fully ionized and ions move through a cloud of free electrons. This model also partially describes electrons moving in the periodic force field of the ion lattice in a solid, but it is not considered a thermodynamic system in the former sense; that concept is reserved for particles that interact only by direct collisions. 


The different counter-forces depend on the situation, and the "construction" refers to the fact that the composition of forces can change drastically, even within a single biological process
and withing a small fraction of nanometer distances. 
The volumes and the  number of particles 
are usually much smaller than those the thermodynamics used to work with; furthermore, the "construction" changes the local physical state point by point. However, the crucial changes happen in small volumes (limited by physical effects) where the \textit{density} is large enough (for a short period)
so we can make
statistically meaningful statements with the mentioned limitations. Handling ions in living matter at least requires much more 
attention. It represents a field (perhaps a sub-discipline or a new discipline) where a new idea of handling is required and which offers hope for describing biological processes.


Classical physics can only handle instantaneous interactions; in the Newtonian worldview, all interactions co-occur. The traditional approach to thermodynamics cannot be applied to biological systems. Erwin Schr√∂dinger stated that \textit{ordinary} scientific laws cannot describe living matter. At the same time, he expressed his conviction that no new force or unknown interaction is emerging; only a previously unknown regularity concept must be found, then the \hypertarget{NonOrdinaryLaws}{non-ordinary laws} organically integrate into the fabric of science, together with the already known laws.

When applied to ions and especially to electrolytes, the conditions for the applicability of the Boltzmann equations are largely not met. Due to the low temperature compared to plasmas, the vast majority of molecules do not dissociate, so they interact only through direct collisions. A minimal number of ions, due to their identical charge, avoids direct collisions with each other through long-range interactions; they do, however, collide with neutral molecules and also the neutral molecules collide with each other. Ions play a leading role in biological processes and can therefore interact through both direct collisions and long-range forces. For this reason, \textit{the Boltzmann equations are certainly not applicable to the description of the processes taking place in electrolytes}, which directly explains why thermodynamics cannot describe processes of life based on electrolytes.
\index{Boltzmann equations}

Further limitations are that, in biological systems, statistical concepts must be applied to a very small number of particles in a closed space of finite volume, where coercive forces also occur, and processes beyond the experimenter's control make it doubtful that we can interpret a closed system. The main problem, however, is that ion's charge and mass are inseparable; furthermore, the speed of the electrostatic interaction of the particles with each other is instantaneous, in accordance with Boltzmann's original assumption. However, the speed of the diffusional interaction, which is calculated from the change in the distribution of the particles, is orders of magnitude slower. Of course, the particle's motion simultaneously changes the strengths of the electrical and thermodynamic interactions. The diffusional effect, given that it is implemented through collisions, occurs only when the particle reaches the region where it changes the concentration, whereas the force field created by the other particles changes immediately.
In biology, the "construction" is also different. In addition to the usually discussed forces, some variable
counter-forces are also present (such as mechanical obstacles represented by membranes, tube walls, and caps on ion channels).
%Another key question is how the particles (in the entire system and in that volume)
%interact with each other. In one major branch, the particles collide
%with each other, but otherwise they do not exert forces on each other.
%In the other, they interact with the long-range Coulomb interaction,
%\index{Coulomb interaction}
%but do not collide.

In mathematics, the temporal gradients are usually described by partial derivatives of
spatial or feature parameters.
The definition of a partial derivative of a function of several variables is its derivative with respect to one of those variables,
\textit{with the others held constant}. In the case of ions, changing the concentration means simultaneously changing the electrical charge; that is, the concentration gradient and the electrical gradient 
depend on each other.
In other words, one cannot calculate the partial derivatives of ions' concentration and electrical potential,
only their total derivative.
As a consequence, equations that calculate the partial derivatives of the concentration and the electrical potential with respect to time are either incorrect or approximations.
The discussions, for example, the one leading to
Eq.~(11.30) in~\cite{KochBiophysics:1999}, assume that the 
interaction speeds are identical and that the partial derivatives 
can be interpreted for ions. Both assumptions are wrong. However,
the claim that "while diffusion is like a hopping flea, electrodiffusion is
like a flee that is hopping in a breeze"~\cite{KochBiophysics:1999} (attributed to Hodgkin) is true; see also our Eq.~(\ref{eq:PhysicsGradientRatio}).


\subsection{Non-ordinary laws\label{sec:Physics-NonOrdinaryLaws}}


Science laws about separate interactions of masses and charges are
based on abstractions, which enable and need approximations and omissions.
While we understand that the speeds of electrical and gravitational
interactions are finite, we can use the 'instant interaction' approximation
in classical physics. This is because one effect of the first particle
reaches the second particle at the same time as the other effect,
leading to the absence of a time-dependent term in the mathematical
formulation (although in special cases the 'retarded interaction' shall be discussed). However, this is not the case in electrodiffusion, where
the mass transfer is significantly slower than the transfer speed
of the electromagnetic field. To describe the interrelation of these
two effects, we need to conduct case studies and apply casual approximations.
\index{instant interaction}
\index{prompt interaction|see{instant interaction}}
\textit{Science uses the notion 'instant' in the sense that one interaction
is much faster than the process under study}; we consider the faster interaction as instant. 


From a physical point of view, \hypertarget{PhysicsLawsOfMotion}{ionic solutions} are confined to a well-defined volume, with no interaction with the rest of the world.
What makes the things more complicated, their volume has evidently finite size with bounding surface(s), so we must adapt the corresponding laws to the case of \hyperlink{ChangingResources}
{finite resources}.
\index{finite resource}
At a microscopic level, on the one hand, we use the abstraction they consist of chargeless and sizeless simple balls with mass, have thermal (kinetic) energy, and collide with each other, as thermodynamics excellently describes it.
\index{laws of motion}
On the other hand, we use another abstraction, which is massless and sizeless charged points with mutual repulsion. 
Combining those different concepts is not possible without conflicts and contradictions. At a microscopic level, in both abstractions, they attempt to distribute as equally as possible in a given volume. 
However, we can notice the difference that the equilibrium 
(nomen est omen) 
is dynamic for the thermodynamic and static for the electrostatic interaction.
At a macroscopic level, we use the abstraction that the respective volume is filled with a continuous medium with uniformly distributed macroscopic parameters such as temperature, pressure, concentration, and potential. 


One can parallelize describing how ions change their position with how Newton's laws of motion relate an object's motion to the forces exerting on it. The first and third laws are \textit{static} ones, the second one is \textit{dynamic}. We can translate the first law to ions that without external invasion, their volume at rest will remain at rest. The third law,
for ions' volume, essentially states that in a resting state at every points the electrostatic and thermodynamic forces are equal; this is expressed by the
\hyperlink{NernstPlanckPositionDerivatives}
{Nernst-Planck electrodiffusion equation} (for the case of no transport).
 The second law, for mechanics, expresses the time course of the object: \textit{the position's time derivative}.
 Notice that in this case we make \textit{one abstraction} that the object (the carrier) has \textit{one attribute}, its mass.
(Recall, how important was for the special theory of relativity that the \textit{accelerated mass} and the \textit{gravitational mass} were identical.) 
 

For ions, we have \textit{two abstractions}, and two attributes \textit{'charge' and 'mass'}, and the two forces act on the two attributes which science classified to belong to different science disciplines. We cannot express easily how the electric and thermodynamic forces will change the object's position because those forces act differently on different attributes.
No \hyperlink{NernstPlanckTimeDerivatives}
{time derivatives} are known,
only \hyperlink{NernstPlanckPositionDerivatives}
{position derivatives}.
Due to this hiatus, physics (and consequently: physiology) cannot describe the electrochemical processes: \textit{the second law of motion for electrodiffusion is missing}.
As a consequence of the instant interaction, \textit{classical science has no mechanism for handling the case
when two different force fields (gradients) having different propagation speeds act on an object
and two different abstractions (charge and mass},
belonging to different science disciplines) translate the force into acceleration. Here we use Boltzmann's idea: we derive the particles' speed
from the continuum mass's speed. Furthermore, our idea is to derive a pseudo-electrical field (see section~\ref{sec:Physics-ElectrolyteThermalField}) and potential to combine those two interactions and their respective disciplines.

When describing processes (i.e., dynamical systems), we must have
one or more equations of motion (aka changing speeds):
how the time gradient of the fundamental entities are changing in the function of the fundamental entities. In classical
science, we have only one fundamental entity: the position and also the driving
forces depend only on the position. The Newtonian laws of motion do not depend on a temporal gradient.
\textit{In 'ordinary' science, we have a single-speed, single-substance interaction} abstraction;
so we have one law of motion; an analytical solution is possible.
%
In the Einsteinian world, speed explicitly appears when describing
the interrelation of fundamental concepts mass, position, and time.
Actually, a tightly related second entity (position and time) appears;
and the speed connects them. 
In all cases, the law has the form of a differential equation;
i.e., we can derive the fundamental entities by integration.
In the case of the dual-speed interaction of ions,  
only numerical solution is possible.



\textit{In our 'non-ordinary' science,
	we have a double-speed, double-substance interaction} abstraction; correspondingly,
we have \textit{two} laws of motion. Furthermore, for ions we use
a continuous and a particle-based approach, sometimes simultaneously.
In our laws of motion (see Eq.(\ref{eq:Nernst-dVdt}) and Eq.(\ref{eq:Nernst-dCdt})) we also have explicit speed dependence 
in describing the interrelation of concentration and potential.
Actually, we are thinking in two entities (concentration and potential),
but both of them are parametrized by position $x$.
In line with the Einsteinian case, the time shines up, and,
again, the speed connects those entities.
However, the different interaction speeds act on the coordinates
differently, that is, the effects of changed entities cannot
be separated. This is why we need 'non-ordinary' laws. 
(Given that our thermodynamical speed is always by orders of magnitude lower
than the electrical (limiting) speed, we neglect transforming the time.)


\index{Nernst-Planck equation}
\index{ equation!Nernst-Planck}

In all cases, the law has the form of a differential equation;
i.e., we can derive the fundamental entities by integration.
\textit{In 'ordinary' science, we have a single-speed interaction} abstraction;
so we have one law of motion; an analytical solution is possible. 
In a non-ordinary case, we have a dual-speed interaction, and a numerical solution is likely the only option.

\subsection{Steady state\label{sec:Physics-SteadyState}}

In volumes containing ions, the ions experience two effects in those two abstractions. When an
invasion in the volume happens, electric potential, pressure, temperature,
or concentration changes locally; dynamic changes begin to restore
its balanced steady state. When the invasion persists, the system
finds another steady state. If the invasion is local and affects only
one macroscopic parameter, another macroscopic parameter(s) may change
at the rest of the locations. An observer experiences that changing
one macroscopic parameter of the system causes an unexpected (and
unexplainable) local change in another macroscopic parameter. \textit{The
microscopic world maps the changes from one abstraction to the other.}
Experimentally, the microscopic world maps the change from the world
of electric abstraction to the world of thermodynamic abstraction
and vice versa. Theoretically, we can do the exact mapping of macroscopic
electrical and thermodynamical parameters using microscopic universal
constants.


The phenomenon of invasion called 'electrodiffusion' means that when
a potential gradient is created in a volume with ions (while its thermodynamical
parameters, such as its volume and temperature, are constant), it
creates a concentration gradient. Conversely, a created concentration
gradient creates a potential gradient.
In a more inclusive form: in a physical system where multiple forces act on the body
(specialized to an ion in electric and thermodynamic fields),
dissipating energy and under constraint forces 
\begin{equation}
	F_{exerting} = F_{electric} + F_{thermodynamic} + F_{friction}   + F_{external} + F_{constraint}
	\label{eq:IonicForces0}
\end{equation}
\noindent
That means when describing an ionic transfer process, \textit{we must not separate the electric current from the mass transfer}: they happen simultaneously and mutually trigger each other. Furthermore,
we must take into account the external force (say clamping), internal friction (moving in viscoseous fluid) and the possible conditional counterforces (such as open/closed ion gates).
 Notice that the thermodynamic term is ion-specific while the other terms are not. To be entirely balanced, the system must be balanced to all elements. In this way, changing one concentration implicitly changes all other concentrations and the electric field.
 Similarly, changing the electrical force by adding an external
 potential, changes the thermodynamic force, and so, the concentrations.
\iflatexml
\else
In terms of our equations, the same equation sounds
\begin{equation}
	F_{exerting} = Eq.(\ref{eq:ElectricGradient}) + Eq.(\ref{eq:NernstPlanckThermal2}) + F_{external} + Eq.(\ref{eq:StokesEinsteinSpeeddV})  + F_{constraint}
	\label{eq:IonicForces}
\end{equation}
\fi


We can describe the equilibrium
state (the mutual dependence of the \emph{spatial gradients} of the
electrical and thermodynamic fields on each other) using the famous Nernst-Planck transport equation 
%
\begin{equation}
	\frac{\partial c}{\partial t} = \nabla \cdot
	\biggl[ \underbrace{D\nabla c}_{Diffusion} -\underbrace{\mathbf{v}c}_{Advection} + \underbrace{\frac{Dqz}{k_{B}T}\mathbf{E}}_{Electromigration} \biggr] 
	\label{eq:NernstPlanckTransport}	
\end{equation}
Unfortunately,  Eq.~(\ref{eq:NernstPlanckTransport}) also comprises the issue specific for ions: it
calculates the not-interpreted partial derivative without taking into account that at least the advection term modifies the local electrical gradient by changing the concentration.
Assuming that the concentration is at equilibrium ($\frac{\partial c}{\partial t}$ = 0; even if its calculation method and its value are questionable), without an external electrical field ($\mathbf{E}$ = 0),
the change due to diffusion (in a statistical sense) is zero, and the flow velocity is zero ($\mathbf{v}=0$),
results in the
\emph{\hypertarget{NernstPlanckPositionDerivatives}{Nernst-Planck
electrodiffusion equation}} in one dimension
%
\index{Nernst-Planck equation}
%
\begin{equation}
\frac{d}{dz}V_{m}(z)=-\frac{RT}{q*F}\frac{1}{C_{k}(z)}\frac{d}{dz}C_{k}(z)\label{eq:NernstPlanck}
\end{equation}
%
\noindent describes the equilibrium
state (the mutual dependence of the \emph{spatial gradients} of the
electrical and thermodynamic fields on each other).
In good textbooks (see, for example,~\cite{KochBiophysics:1999},
Eq (11.28)), its derivation is exhaustively detailed. In the
equation, $z$ is the spatial variable across the direction of the
changed invasion parameter, $R$ is the gas constant, $F$ is the
Faraday's constant, $T$ is the temperature, $q$ the valence
of the ion, ${V_m(z)}$ the potential, and ${C_k(z)}$ the concentration
of the chemical ion. In simple words, it states that the change in
concentration of ions creates a change in the electric field (and
vice versa), and in a stationary state, they remain unchanged. However,
in the classic science there is no way to take into account the
field's propagation speed.
We must call attention to a nuance: to keep balance, the concentration and the potential must change in opposite directions. However, since they are implemented by ions, moving an ion's
mass changes the ion's charge in the same direction.
We note one more feature, that since the potential is linearly proportional to the concentration (and so are their derivatives), the function is of form $f(x) = - \frac{1}{x}$, where, \textit{as an exception, the square of the first derivative equals the second derivative: $f^{\prime\prime}(x)=(f^{\prime}(x))^2$}.



It is one of the rare cases when the starting point was wrong,
but the conclusion was right.
In Eq~(\ref{eq:NernstPlanckTransport}),  
an identical speed for all interactions was assumed.
The equation is a rearranged flux equation, where 
an identical speed for all interactions was assumed. Although the equation is not really applicable for describing the transport of ions (in its practical applications, the identical speed
was calculated as a "mean-field", where the "mean" stands for some average
of interaction speeds differing by several orders of magnitude), in an equilibrium state, the actual value of both
interaction speeds is zero, so they have the same value; furthermore, no advection takes place. This way, the wrong partial derivative is irrelevant. 


It is a serious difficulty with using Eq.(\ref{eq:NernstPlanck}) that it relates entirely different
quantities, so it is not easy to apply it. There exist attempts to interpret the task of transporting ions under
the effect of several interactions with different speeds (for a review,
see~\cite{Poisson-Boltzmann-Nernst-Planck:2011}). However, "a
\emph{mean-field approximation} of ion interactions and continuum
descriptions of concentration and electrostatic potential" actually
means \emph{averaging gradients propagating with speeds $10^8\ m/s$
(electromagnetic interaction) and $10^1\ m/s$ (ionic current), respectively,
which is not appropriate for either (any way of averaging).} The computational
methods need position-dependent diffusion coefficient profiles, and
in addition, they are generally quite limited for most confined regions
such as ion channels. For this reason, they have joint issues, limitations,
and high computational complexity; furthermore, biophysics~\cite{KochBiophysics:1999}
explains, "while diffusion is like a hopping flee, electrodiffusion
is like a flee that is hopping in a breeze". This sentence is the
complete mathematical description of a state change. \emph{The lack
of notion of non-infinite interaction speed does not enable theory
to say anything}. The theory considers the \emph{process} as just
a momentary "hop" between two \emph{states}, although it
admits that there are longer and much shorter moments. Classic theory
has no idea what to do with non-infinite interaction speeds. \emph{This
mistake is a significant obstacle, among others, when attempting to
comprehend how the electrochemical charge handling implements neuronal
computation and information transfer, furthermore, the life itself. }

In 'ordinary' physics, where the charge and mass are independent,
changing one side changes the other in the opposite direction.
In 'non-ordinary' physics, valid for electrolytes, the two differentials must change in the same direction
given that ions' charge and mass cannot be separated.
Correspondingly, when initiating an \gls{AP} in a neuron, the rush-in of ions
increases both concentration and potential simultaneously. 
Moreover, to restore equilibrium, the gradients of the two macroscopic parameters must have the same sign, since they refer to the same ion.
The thermodynamic force acting on an ion is added to the electrical force.
The two are inseparable; the magnitude of the force is 'falsified'. 



\subsection[Laws of motion]{Laws of motion: time derivatives\label{sec:Nernst-time-derivatives}\label{sec:Physics-LawsOfMotion}}


To derive laws of motion of ions in electrolytes, one must use non-ordinary methods after scrutinizing which approximation can be used for living matter.  Below, we derive an approach that enables us to handle interaction speeds that differ by orders of magnitude. Science has created abstract concepts such as space and time; mass and charge. Modern physics was born when experiments began to contradict the fact that nature could be described in such simple terms. The recognition of the non-continuity of energy led to the creation of quantum mechanics, and the recognition of the non-independence of space and time led to the creation of the theory of relativity, with far-reaching consequences. We understood that under certain circumstances, we must treat particles as kinds of continuous waves, and continuous waves as kinds of particles. We understood that the Newtonian approach has limitations, and that interactions at finite speeds can only be described by a different kind of mathematics, namely the concept of spacetime. Moreover, mass is also related to space and time; taking this into account, we can describe nature in terms of curved spacetime. According to classical physics, we can describe phenomena with sufficient accuracy using only the aforementioned concepts (the zeroth derivatives). According to modern physics, for a more accurate description, we must take into account the first derivative with respect to time. For a general description, we must consider the second derivative as well.

Regarding ions, we can handle their charge and mass separately; we know the relevant laws. However,
in the case of ions, we must connect charge and mass, just as in the case of the theory of relativity, space and time. Interestingly,
here too, the velocity creates the connection between the two abstract features. Furthermore, we must introduce a relation for the currents carried by ions, similar to that introduced in statistical mechanics for the correspondence between the particle and the continuum views. However, in our case, the correspondence is established on geometric grounds.


Eq.(\ref{eq:NernstPlanck}) describes a stationary state with no ionic
movement. Deriving a time course (\hypertarget{NernstPlanckTimeDerivatives}{time derivatives}) from the position
derivatives is not possible in a strict mathematical sense. However,
we can provide it by using physical principles.
We consider the electric ion current represented by viscous charged
fluids \cite{ViscousChargedFluids:2014}. As expected, selecting the
speed (aka calculating the appropriate value of the macroscopic speed, see Eq.(\ref{eq:StokesEinsteinSpeed2}))
plays a key role, especially since we are at the boundaries of physics
abstractions; among others, we are mixing microscopic and macroscopic
notions. The actual speed model depends on the concrete case; see
section~\ref{sec:Calculating-ion's-speed}.


In classical
physics, because of the lack of time-dependent terms in the expressions,
the changes are described by position-dependent terms (\emph{position
derivatives}), both in the case of electromagnetical and electrodiffusional
interactions. In classical ('instant interaction') science, the
time derivatives are either not interpreted or can be derived by scaling through
the externally derived joint interaction speed as a scale factor. As explained, we can
extend the idea to enormously different speeds and derive time derivatives
if we consider the faster interaction to be instant.


In the timeless classical physics, there is no explicit dependence on
the time: everything happens simultaneously. In a resting state, the
Maxwell equations essentially follow from the conservation of energy.
One form of energy transforms into another form, and the system arrives
in another balanced state. The carriers of the force fields are continuous and have no masses,
so one can calculate and make infinitesimal changes in the driving
forces; they do not change the system's energy. If one gradient changes,
the other automatically (per definitionem) changes in the opposite direction. In another
words: the driving forces are permanently balanced, the magnetical and
electrical forces act instantly ("at the same time") and they are
always of opposite sign. A time derivative cannot be interpreted:
everything happens at the same time; in other words, at the same space-time
(in the classic interpretation, the time is the same at any point).

In an electrodiffusional process, we start with the same
point of view. We assume that the thermodynamical and electrical driving
forces are equal in an equilibrium state. That assumption results
in the Nernst-Planck equation. On one side, we use a macroscopic parameter,
the potential. On the other side, we use another macroscopic
parameter, the concentration. The equation bridges those
macroscopic parameters by using universal constants from the microscopic world. 

At first glance, the case is similar to that of electrical and magnetic fields.
However, we cannot
make infinitesimally small changes in the gradient since the carrier
of the force fields is "atomic". Furthermore, moving it infinitesimally
(changing only its position coordinates), the changes in the electrical
and thermodynamic gradients do not result in a new balanced state.
The effect of ions' \emph{charge} has an immediate effect on the volume,
but ion's \emph{mass} has a delayed effect. The infinitesimally small
change in the position results in an infinitesimally small increase
in the energy of the system, given that moving a carrier changes the
potential and the concentration in the same direction, since we did not
consider that the
time coordinate changes as well.
In the Newtonian world, everything
happens at the same time, so we cannot handle instant and finite interaction
speeds simultaneously.
Eq.~(\ref{eq:Nernst1}) contradicts energy conservation.
The infinitesimally small energy change disappears
only when the effect of the slower interaction reaches the other carriers in the
volume. \textit{When the interaction speeds differ, energy conservation is valid only if one uses space-time.}




Fortunately, we can derive the infinitely small change where
the time and space (position) coordinates are connected; essentially, in the same way as in
the special theory of relativity. Let us assume that the gradients
act on the mass and the charge, but the ion's effects on the gradients
are negligible. According to the principle of relativity,
\emph{the phenomena must remain the same in a reference frame moving with a constant speed} \emph{relative to the first one},
and we choose the
system that moves together with the ion. In the second frame, no ionic
movement occurs along the movement's direction. 
In line with the fact that the speed of light is independent of the reference frame,
we assume that the higher interaction speed remains the same in both
systems: it is instant. 
The observers in both reference frames must see that the
system is balanced. The difference is that in the first frame, the
system is \textit{statically} balanced (no change in the gradients, but the
ion is moving), and in the second one, it is \textit{dynamically} balanced (the
gradients change to keep the ion at rest).
\emph{The gradients the
moving ion experiences are the ones that the standing ion experiences
at another time (depending on its speed). This way, we can provide
the needed time course of the process.} 

Compared with the electromagnetic case, we see crucial differences.
First, the mass's propagation speed (forming a new concentration gradient) is millions of times lower than
the charge's. Second, the moving ion simultaneously represents
mass transport and charge transport.
Third, when deriving position derivatives, we conclude from the assumption that
there is no movement (in other words, no explicit dependence on the
time): the effect of the electrical and magnetic driving forces is
equal, whatever time is needed to reach that balanced state. In contrast, in 
electrodiffusion, the velocity changes the concentration gradient, and simultaneously, the
potential gradient. 


We assume that equation~(\ref{eq:NernstPlanck}) is valid for a given time
$t$.
At time $t+dt$, in another steady state, the two interactions
manifest at different times: we have
%
\begin{equation}
\frac{d}{dz}V_{m}(z+v(z)*dt)=-\frac{RT}{q*F}\frac{1}{C_{k}(z)}\frac{d}{dz}C_{k}(z)\label{eq:Nernst-1V}
\end{equation}
%
\noindent or, equivalently, it can be expressed as
%
\begin{equation}
\frac{d}{dz}C_{k}(z-v(z)*dt)=-\frac{q*F}{RT}C_{k}(z)\frac{d}{dz}V_{m}(z)\label{eq:Nernst-1C}
\end{equation}

\noindent The concentration at position $z$ determines the potential
(apart from an integration constant) at position:
%
\begin{equation}
dV_{m}(z)=dz*\frac{d}{dz}V_{m}(z)=-dz\frac{RT}{q*F}\frac{1}{C_{k}(z)}\frac{d}{dz}C_{k}(z)\label{eq:Nernst-2V}
\end{equation}
so (and here the constant disappears) the time derivative is
%
\begin{equation}
\frac{d}{dt}V_{m}(z)=v(z)*\frac{d}{dz}V_{m}(z)=-v(z)*\frac{RT}{q*F}\frac{1}{C_{k}(z)}\frac{d}{dz}C_{k}(z)\label{eq:Nernst-dVdt}
\end{equation}
or
\begin{equation}
\frac{d}{dt}V(z)=\frac{D*R}{F}*C(z)*\frac{dC}{dz}*\frac{RT}{q*F}\frac{1}{C(z)}\frac{d}{dz}C_{k}(z)\label{eq:Nernst-dVdt2}
\end{equation}

\noindent Similarly, at time $t-dt$, in another steady state, we
have
%
\begin{equation}
dC_{k}(z-v(z)*dt)=dz*\frac{d}{dz}C_{k}(z)=-dz\frac{q*F}{RT}V_{m}(z)\frac{d}{dz}V_{m}(z)\label{eq:Nernst-2C}
\end{equation}
\begin{equation}
\frac{d}{dt}C_{k}(z)=v(z)*\frac{d}{dz}C_{k}(z)=-v(z)\frac{q*F}{RT}V_{m}(z)\frac{d}{dz}V_{m}(z)\label{eq:Nernst-dCdt}
\end{equation}



We expressed the dependence of gradients on each other using the ion's speed $v$ as intermediate variable, that can be expressed by the Stokes-Einstein relation as
\begin{equation}
	v= -\frac{D*R}{F}*C(z)*\frac{dC}{dz}
	\label{eq:StokesEinsteinSpeed2}
\end{equation}
After simplifying the expression and using the aforementioned special feature of the $\frac{1}{x}$ type function
\begin{equation}
	\frac{dV(z)}{dt}=\frac{D*R*R*T}{q*F*F}*\frac{dC(z)}{dz}*\frac{dC(z)}{dz}\label{eq:Nernst-dVdtDR}
\end{equation}
%
\begin{equation}
	\frac{dV}{dt}=\biggl(\frac{T*R^2}{q*F^2}\biggr)*D*\frac{d^2C}{dz^2}
	\label{eq:FickSecondElectrodiffusion}
\end{equation}


%
As section~\ref{sec:PHYSICS_MEASURINGOSCILLATOR} discusses, in general, the electric operation
of an electrolyte can be described by this law of motion. For practical calculations, the voltage time derivative can be calculated directly from the input current, thereby accounting for the current production mechanism, see equations (\ref{eq:I_Out}) and~(\ref{eq:PSPderivative}), which directly consider the current production mechanism.
We must not forget that we started 
from a quasi-equilibrium state; that is, our description is valid only for quasi-static processes.

We note here that in closed volumes, for example, see Schr√∂dinger's points on the specific aspects of life, one must consider further effects.
The electrostatic forces of the ions exerted on
each other, and the wall exerts a counterforce 
on the ions in the microscopic view, and on the fluid in the macroscopic view, which manifests as a mechanical force and pressure.
This aspect is not considered in the general transport equation~(\ref{eq:NernstPlanckTransport}); one must add one more term
when calculating mass transport.
If the volume is not hermetically closed (say, the ion channels in the 
wall of the membrane represent a "hole" for the ions), the combined 
electrostatic plus mechanical pressure can provide a driving force (instead of hypothesizing a magic protein mechanism)
\index{protein!mechanism}
for producing a mass transport. If the change in concentration and potential happens suddenly (see the rush-in of $Na^+$ ions at the
beginning of an \gls{AP} in neurons), that "explosion" creates an "impact force" exerting on the membrane
and the conterforce starts a pressure wave and other mechanical changes, as discussed in~\cite{MechanicalPropertiesNerves:2025}. The elastic membrane 
generates 
\textit{The electrical and thermodynamic phenomena are just two sides of the same coin} as discussed in~\cite{VeghMembranePotential:2025},
and underpinned by
some plausible numericals estimations in "speculations"

 Fortunately, 
the overwhelming majority of the energy of the excitation
is stored as elastic energy of the membrane, and the pressure is proportional to the measurable voltage, so describing the electrical behavior is sufficient to provide a sufficiently precise description
of the processes in the membrane, but one has to keep in mind
that the force is composed of electrical and thermodynamic components.


\subsection[Nernst's law]{Nernst's law\label{sec:Physics-NernstLaw}}
\index{Nernst's Law}
In a segmented electrolyte, the electric charges are typically globally balanced; however, they may become unbalanced locally due to physical reasons.
 The two sides of Eq.(\ref{eq:NernstPlanck}) are the derivatives of the equation
\begin{equation}
	V_{C_{k}} =\frac{RT}{q*F}\ln{\biggl(\frac{C_{k}^{ext}}{C_{k}^{ref}}\biggr)}\label{eq:Nernst1}
\end{equation}

\noindent \hypertarget{NernstLaw}{known as \textit{Nernst equation}}.  In other words, \textit{Eq.(\ref{eq:NernstPlanck}) and Eq.(\ref{eq:Nernst1}) are the differential and integral formulations of the same knowledge}. The limits of the integration are chosen arbitrarily (by choosing the reference concentration).
Hence, the derived potentials inherently comprise an additive term (a potential difference), so they are not intercomparable directly if they use a different reference $C_{k}^{ref}$.
The derivatives are spatial derivatives; the temporal derivatives (needed for describing the time course) of the concentration(s) and voltage are derived above and in~\cite{VeghNon-ordinaryLaws:2025}.
(Eq.~(\ref{eq:Nernst1}) results in opposite signs according to the 'ordinary' and 'non-ordinary' laws of physics. Experience shows that the 'non-ordinary' laws result in the correct sign.)

The Nernst potential (or reversal potential) is the specific membrane voltage where the net flow of a particular ion across a cell membrane stops, balancing the chemical concentration gradient with the electrical gradient, described by the Nernst equation. It's calculated using the ion's concentration ratio, its charge (valence), and temperature, indicating the potential at which an ion is in electrochemical equilibrium.
At the level of ions, the equilibrium means that the membrane potential 
equals the Nernst-potential calculated from Eq.(\ref{eq:Nernst1})

Understanding the difference between Nernst potential, reversal potential and equilibrium potential crucial for understanding neuronal signaling and cell function.
In addition to the membrane's potential (discussed in section~\ref{sec:Physics-TwoSegments}, defined by the membrane's parameters) and the Nernst potential (see Eq.(\ref{eq:Nernst1}), defined by the concentrations),
an external potential can also be present in the system.
If only one type of ions is present on the two sides of the membrane, the charge transport (ion current) stops when the external potential exactly counterbalances the difference of the first two terms.
As the name of the reversal potential suggests, at that external voltage value the current through the membrane reverses (changes its sign).

The case and the concepts are different if more than one ion is present
in the two segments. The Nernst voltage is ion specific, so each ion must be at its reversal potential to be at an equilibrium potential.
If it is not the case (and usually it is not so), the individual Nernst potentials are different, so a driving force exists for all ions.
This situation results in permanent material transport for all ions
until the concentrations get equal. The so called pumps work
simply because that driving force permanently exists: a vast amount of 
$Na^+$ ions must be removed after generating an \gls{AP}; inputting
$K^+$ is needed to keep the electric balance of charges.
It is a misunderstanding that the resting potential is the weighted average of the Nernst voltages; see section~\ref{sec:Physics-ElectricalField}.
 


 

The Nernst equation is valid only in a system 
at equilibrium with no material flow (it cannot be interpreted for transient states, such as generating \gls{AP} in a cell).
The limits of the integration are chosen arbitrarily (by choosing the reference concentration $C_{k}^{int}$).
Hence, the derived potential values inherently include an additive term (a potential difference), so one must not compare them directly if they use different reference potentials $C_{k}^{int}$.
Furthermore, it is nonsense to combine the quantities from the intracellular and extracellular sides additively,
whether concentrations, or mobilities, or Nernst voltages, as it happens in the \gls{GHK} equation, see section~\ref{sec:Physics-Goldman-Hodgkin-Katz} and~\cite{VeghMembranePotential:2025}.


\subsection{Fick's Law\label{sec:Fick-Electrodiffusion}}
\index{Fick's Law}

By expressing the speed through the Stokes-Einstein relation, see Eq.(\ref{eq:StokesEinsteinSpeeddC})
\begin{equation}
	\frac{dV}{dt}=\frac{D*R*R*T}{q*F*F}*\frac{d^2C}{dx^2}=\biggl(\frac{T*R^2}{q*F^2}\biggr)*D*\frac{d^2C}{dx^2}\label{eq:Nernst-dVdtStokes}
\end{equation}
%
Or, alternatively,
%
\begin{equation}
	\frac{dV}{dt} = \Bigl(\frac{T*R}{F}\Bigr)^2\frac{k}{6*q*\pi*\eta*a}*\frac{d^2C}{dx^2} \label{eq:Nernst-dVdt1}
\end{equation}

Given that 
\begin{equation}
\frac{dV}{dt}= D*\frac{d^2C}{dx^2}\label{Fick'sSecond}
\end{equation}
expresses Fick‚Äôs Second Law of Diffusion, we can derive 
the ratio between the electric and thermodynamic temporal gradients.
Using values 
$T=300\ K$, $q=1$, $F=\ 96495\ A*s/mol$, $R=8.31446261815324\ J*K^{-1}*mol^{-1}$
\begin{equation}
	\frac{dV}{dt}=2.23*10^{-6}*D*\frac{d^2C}{dx^2} = \mathbf{2.23*10^{-6}}\frac{dC}{dt}\label{eq:PhysicsGradientRatio}
\end{equation}

We can provide a rough (experimental) estimation of the value. The time course of the gradient (half-width) in Figure 2.2 in \cite{JohnstonWuNeurophysiology:1995}  was produced in~$0.3*10^3~ s$. Reciprocally, a voltage gradient needs $0.1*10^{-3}\ s$
to produce the same concentration gradient, see
Fig.~2d in~\cite{BeanActionPotential:2007}. Their ratio is\ $3*10^{-6}$.
The other way round, when we assume that the propagation of the electric field in the solution is $2*10^{8}\ m/s$ and multiply it by the factor above, we arrive at the speed of ion's speed in the range around $10^{2}\ m/s$.

Given that we can assume that the electrical interaction speed is
about the respective speed of light, we arrive at
that the speed of material transport (the speed of the mechanical wave) is about \SI{100}{[\meter\per\second]}. Given that the mechanical wave 
carries an electric charge, it induces an electrical charge on the other side
of the axon. This way, the particles move under the combined effect of a thermodynamic force and an electrical force. The amount of induced charge depends on the specific capacity 
of the axon (the thickness of the myelin layer on it), so the resultant
force (and, due to this, the Stokes-Einstein speed) of the 
axonal current depends on the thickness of the myelin layer.


